{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wav2Vec2 Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sally/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/sally/anaconda3/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "\n",
    "model_id = \"facebook/wav2vec2-lv-60-espeak-cv-ft\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_id)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuned 1 (ljspeech_phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sally/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/sally/anaconda3/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "\n",
    "model_id = \"bookbot/wav2vec2-ljspeech-gruut\"\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForCTC.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuned 2 (timit_english_timit-4k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sally/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/sally/anaconda3/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"excalibur12/wav2vec2-large-lv60_phoneme-timit_english_timit-4k\")\n",
    "model = AutoModelForCTC.from_pretrained(\"excalibur12/wav2vec2-large-lv60_phoneme-timit_english_timit-4k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phonemize_audio(audio_path):\n",
    "    speech, sr = librosa.load(audio_path, sr=16000) # resamples to 16,000Hz\n",
    "    input_values = processor(speech, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    phonemes = processor.batch_decode(predicted_ids)\n",
    "    return phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def record_audio(filename, duration=3, sample_rate=16000):\n",
    "    directory = os.path.dirname(filename)\n",
    "    if directory and not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Created directory: {directory}\")\n",
    "\n",
    "    print(f\"--- Recording started for {duration} seconds ---\")\n",
    "    \n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "    \n",
    "    sd.wait()\n",
    "    \n",
    "    print(\"--- Recording finished ---\")\n",
    "    \n",
    "    write(filename, sample_rate, recording)\n",
    "    return filename\n",
    "\n",
    "# record_audio(\"scope_phoneme_data/test/test_record.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record & Run Recognizer Realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recording started for 3 seconds ---\n",
      "--- Recording finished ---\n",
      "['aÀê s s d']\n"
     ]
    }
   ],
   "source": [
    "file_name = \"scope_phoneme_data/test/test_record.wav\"\n",
    "record_audio(file_name)\n",
    "print(phonemize_audio(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Recognizer for all SCOPE Phoneme Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Folder/Label     File Name    Predicted Phonemes\n",
      "0       O long  O long 4.wav      [h# pau q ow h#]\n",
      "1       O long  O long 1.wav            [h# ow h#]\n",
      "2       O long  O long 3.wav            [h# ow h#]\n",
      "3       O long  O long 2.wav          [h# q ow h#]\n",
      "4            J       J 3.wav  [h# hh dcl jh ah h#]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"data/scope_phoneme_data\"\n",
    "data_records = []\n",
    "\n",
    "for folder_name in os.listdir(data_path):\n",
    "    folder_path = os.path.join(data_path, folder_name)\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".wav\"):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                phonemes = phonemize_audio(file_path)\n",
    "                \n",
    "                data_records.append({\n",
    "                    \"Folder/Label\": folder_name,\n",
    "                    \"File Name\": file_name,\n",
    "                    \"Predicted Phonemes\": phonemes\n",
    "                })\n",
    "\n",
    "df = pd.DataFrame(data_records)\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv(\"phoneme_timit_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
